# docker-compose.yml para levantar el microservicio ASR
services:
  asr:
    build:
      context: ../services/asr
      dockerfile: Dockerfile
    container_name: asr_service
    ports:
      - "8001:8000"  # El Dockerfile expone el 8000, mapeamos al 8001 del host
    environment:
      - PYTHONUNBUFFERED=1
    volumes:
      - ../services/asr:/app  # Monta el código fuente para desarrollo
      # Los modelos de Whisper se descargarán automáticamente por el microservicio ASR según requirements.txt
    restart: unless-stopped
    # Si necesitas GPU, añade:
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
  ingestion:
    build:
      context: ../services/ingestion
      dockerfile: Dockerfile
    container_name: ingestion_service
    environment:
      - PYTHONUNBUFFERED=1
    volumes:
      - ../services/ingestion:/app
      - ../docs/dataset_procedures:/app/docs/dataset_procedures
      # - ../common/vector_db:/app/common/vector_db
      # - ../common/embedders:/app/common/embedders
    depends_on:
      - chromadb
    # Si necesitas GPU, añade:
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  agentic_react:
    build:
      context: ../services/agentic_react
      dockerfile: Dockerfile
    container_name: agentic_react_service
    environment:
      - PYTHONUNBUFFERED=1
    volumes:
      - ../services/agentic_react:/app
      # - ../common/vector_db:/app/common/vector_db
      - ../common/embedders:/app/common/embedders
      # - ../models_data/llms/mistral_models/7B-Instruct-v0.3:/app/models_data/llms/mistral_models/7B-Instruct-v0.3
    ports:
      - "8002:8000" # host:8002 → contenedor:8000
    depends_on:
      - asr
      - chromadb
      - ollama
    # Si necesitas GPU, añade:
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
  chromadb:
    image: chromadb/chroma
    container_name: chromadb_service
    volumes:
      - ../common/vector_db:/data
    ports:
      - "8003:8000"
  ollama:
    build:
      context: ../services/ollama
      dockerfile: Dockerfile
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
volumes:
  ollama:


